{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36aba985",
   "metadata": {},
   "source": [
    "# Overcooked Tutorial\n",
    "This Notebook will demonstrate a couple of common use cases of the Overcooked Ai Library, including loading and evaluating agents and visualizing trajectories. Ideally we will have a Colab notebook you can interact with, but sadly Colab only supports python 3.10 kernel, and currently there are problems loading files pickled in 3.7 environment. As a compromise we created this notebook where you can see some examples of the most frequently used methods after they are executed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6b8ba",
   "metadata": {},
   "source": [
    "# 0): Training you agent\n",
    "The most convenient way to train an agent is with the [ppo_rllib_client.py](https://github.com/HumanCompatibleAI/overcooked_ai/blob/master/src/human_aware_rl/ppo/ppo_rllib_client.py) file, where you can either pass in the arguments through commandline, or you can directly modify the variables you want to change in the file. \n",
    "\n",
    "You can also start an experiment in another python script like the following, which can sometimes be more convenient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a035be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MediumLevelActionManager\n",
      "Computing MediumLevelActionManager\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "857c87f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MediumLevelActionManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'both_agent_obs': (array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1.,  0.,  0., -1.,\n",
       "          2.,  0.,  0.,  0.,  0.,  2., -1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0., -2.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0., -2.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0., -1., -2.,  0.,  0.,  2.,  1.,  0.,  0.,  0.,  0.,  2.,\n",
       "         -2.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,\n",
       "          1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  3., -1.,  0.,  1.,  0.,\n",
       "          1., -5.,  1.,  6.,  2.]),\n",
       "  array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -2.,  0.,  0.,  2.,\n",
       "          1.,  0.,  0.,  0.,  0.,  2., -2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  3.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  3., -1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0., -1., -1.,  0.,  0., -1.,  2.,  0.,  0.,  0.,  0.,  2.,\n",
       "         -1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
       "          1.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  1.,  1.,  0.,  0.,\n",
       "          0.,  5., -1.,  1.,  3.])),\n",
       " 'overcooked_state': <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState at 0x7f747818ba90>,\n",
       " 'other_agent_env_idx': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "288e199c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'both_agent_obs': (array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1.,  0.,  0.,  2.,\n",
       "           2.,  0.,  0.,  0.,  0.,  2., -1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0.,  3.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  3.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0., -1., -1.,  0.,  0., -1.,  2.,  0.,  0.,  0.,  0.,  2.,\n",
       "          -1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  0.,\n",
       "           1.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -2.,  1.,  1.,  0.,  0.,\n",
       "           0.,  5.,  0.,  1.,  2.]),\n",
       "   array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1.,  0.,  0., -1.,\n",
       "           2.,  0.,  0.,  0.,  0.,  2., -1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "           0.,  0.,  0.,  0., -2.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "           0., -2.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "           0.,  0., -1., -1.,  0.,  0.,  2.,  2.,  0.,  0.,  0.,  0.,  2.,\n",
       "          -1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,\n",
       "           1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  1.,  0.,  0.,  0.,\n",
       "           1., -5.,  0.,  6.,  2.])),\n",
       "  'overcooked_state': <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState at 0x7f741de28580>,\n",
       "  'other_agent_env_idx': 0},\n",
       " 0,\n",
       " False,\n",
       " {'agent_infos': [{}, {}],\n",
       "  'sparse_r_by_agent': [0, 0],\n",
       "  'shaped_r_by_agent': [0, 0],\n",
       "  'phi_s': None,\n",
       "  'phi_s_prime': None,\n",
       "  'policy_agent_idx': 1})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9bd5b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60521ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_aware_rl.ppo.ppo_rllib_client import ex\n",
    "# For all the tunable paramters, check out ppo_rllib_client.py file\n",
    "# Note this is not what the configuration should look like for a real experiment\n",
    "config_updates = {\n",
    "    \"results_dir\": \"path/to/results\", #change this to your local directory\n",
    "    \"layout_name\": \"cramped_room\",\n",
    "    \"clip_param\": 0.2,\n",
    "    'gamma': 0.9,\n",
    "    'num_training_iters': 10, #this should usually be a lot higher\n",
    "    'num_workers': 1,\n",
    "    'num_gpus': 0,\n",
    "    \"verbose\": False,\n",
    "    'train_batch_size': 800,\n",
    "    'sgd_minibatch_size': 800,\n",
    "    'num_sgd_iter': 1,\n",
    "    \"evaluation_interval\": 2\n",
    "}\n",
    "run = ex.run(config_updates=config_updates, options={\"--loglevel\": \"ERROR\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de10c0",
   "metadata": {},
   "source": [
    "One can check the results of the experiment run by accessing **run.result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44455fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_sparse_reward': 0.0, 'average_total_reward': 14.290098302224868}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run.result\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f96f8",
   "metadata": {},
   "source": [
    "In practice, the reward should be much higher if optimized. Checkout the graph in the [README](https://github.com/HumanCompatibleAI/overcooked_ai/tree/master/src/human_aware_rl) in human_aware_rl module for baseline performances.\n",
    "\n",
    "Similarly, you can train BC agents with the [reproduce_bc.py](https://github.com/HumanCompatibleAI/overcooked_ai/blob/master/src/human_aware_rl/imitation/reproduce_bc.py) file under the human_aware_rl/imitation directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f493c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/jacksonyan/Desktop/project_with_Micah/overcooked_ai/src/human_aware_rl/static/human_data/cleaned/2019_hh_trials_train.pickle\n",
      "Number of trajectories processed for each layout: {'cramped_room': 14}\n",
      "Train on 28539 samples, validate on 5037 samples\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - tensorflow - OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28539/28539 - 1s - loss: 0.9522 - sparse_categorical_accuracy: 0.7216 - val_loss: 0.8845 - val_sparse_categorical_accuracy: 0.7058 - lr: 0.0010 - 576ms/epoch - 20us/sample\n",
      "Epoch 2/10\n",
      "28539/28539 - 0s - loss: 0.8393 - sparse_categorical_accuracy: 0.7250 - val_loss: 0.8123 - val_sparse_categorical_accuracy: 0.7036 - lr: 0.0010 - 354ms/epoch - 12us/sample\n",
      "Epoch 3/10\n",
      "28539/28539 - 0s - loss: 0.8052 - sparse_categorical_accuracy: 0.7262 - val_loss: 0.7980 - val_sparse_categorical_accuracy: 0.7032 - lr: 0.0010 - 355ms/epoch - 12us/sample\n",
      "Epoch 4/10\n",
      "28539/28539 - 0s - loss: 0.7869 - sparse_categorical_accuracy: 0.7244 - val_loss: 0.7843 - val_sparse_categorical_accuracy: 0.7020 - lr: 0.0010 - 354ms/epoch - 12us/sample\n",
      "Epoch 5/10\n",
      "28539/28539 - 0s - loss: 0.7748 - sparse_categorical_accuracy: 0.7239 - val_loss: 0.7741 - val_sparse_categorical_accuracy: 0.7070 - lr: 0.0010 - 385ms/epoch - 13us/sample\n",
      "Epoch 6/10\n",
      "28539/28539 - 0s - loss: 0.7669 - sparse_categorical_accuracy: 0.7227 - val_loss: 0.7693 - val_sparse_categorical_accuracy: 0.7044 - lr: 0.0010 - 361ms/epoch - 13us/sample\n",
      "Epoch 7/10\n",
      "28539/28539 - 0s - loss: 0.7597 - sparse_categorical_accuracy: 0.7231 - val_loss: 0.7635 - val_sparse_categorical_accuracy: 0.7050 - lr: 0.0010 - 344ms/epoch - 12us/sample\n",
      "Epoch 8/10\n",
      "28539/28539 - 0s - loss: 0.7563 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.7620 - val_sparse_categorical_accuracy: 0.7048 - lr: 0.0010 - 357ms/epoch - 13us/sample\n",
      "Epoch 9/10\n",
      "28539/28539 - 0s - loss: 0.7527 - sparse_categorical_accuracy: 0.7231 - val_loss: 0.7530 - val_sparse_categorical_accuracy: 0.7020 - lr: 0.0010 - 352ms/epoch - 12us/sample\n",
      "Epoch 10/10\n",
      "28539/28539 - 0s - loss: 0.7488 - sparse_categorical_accuracy: 0.7246 - val_loss: 0.7551 - val_sparse_categorical_accuracy: 0.6986 - lr: 0.0010 - 352ms/epoch - 12us/sample\n",
      "Saving bc model at  path/to/bc_dir\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fc0eff12590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = \"cramped_room\" # any compatible layouts \n",
    "from human_aware_rl.imitation.behavior_cloning_tf2 import (\n",
    "    get_bc_params, # get the configuration for BC agents\n",
    "    train_bc_model, # train the BC model\n",
    ")\n",
    "from human_aware_rl.static import (\n",
    "    CLEAN_2019_HUMAN_DATA_TRAIN, # human trajectories\n",
    ")\n",
    "\n",
    "params_to_override = {\n",
    "    # this is the layouts where the training will happen\n",
    "    \"layouts\": [layout], \n",
    "    # this is the layout that the agents will be evaluated on\n",
    "    # Most of the time they should be the same, but because of refactoring some old layouts have more than one name and they need to be adjusted accordingly\n",
    "    \"layout_name\": layout, \n",
    "    \"data_path\": CLEAN_2019_HUMAN_DATA_TRAIN,\n",
    "    \"epochs\": 10,\n",
    "    \"old_dynamics\": True,\n",
    "}\n",
    "\n",
    "bc_params = get_bc_params(**params_to_override)\n",
    "train_bc_model(\"path/to/bc_dir\", bc_params, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc068ebc",
   "metadata": {},
   "source": [
    "# 1): Loading trained agents\n",
    "This section will show you how to load a pretrained agents. To load an agent, you can use the load_agent function in the [rllib.py](https://github.com/HumanCompatibleAI/overcooked_ai/blob/master/src/human_aware_rl/rllib/rllib.py) file. For the purpose of demonstration, I will be loading a local agent, which is also one of the agents included in the web demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844332c3",
   "metadata": {},
   "source": [
    "## 1.1): Loading PPO agent\n",
    "The PPO agents are all trained via the Ray trainer, so to load a trained agent, we can just use the load_agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aeaae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:02:16,984\tWARNING deprecation.py:48 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<human_aware_rl.rllib.rllib.RlLibAgent at 0x7fc0ecf90ed0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from human_aware_rl.rllib.rllib import load_agent\n",
    "agent_path = \"src/overcooked_demo/server/static/assets/agents/RllibCrampedRoomSP/agent\"\n",
    "# The first argument is the path to the saved trainer, we then loads the agent associated with that trainner\n",
    "## If you use the experiment setup provided, the saved path should be the results_dir in the configuration\n",
    "# The second argument is the type of agent to load, which only matters if it is not a self-play agent \n",
    "# The third argument is the agent_index, which is not directly related to the training\n",
    "## It is used in creating the RllibAgent class that is used for evaluation\n",
    "ppo_agent = load_agent(agent_path,\"ppo\",0)\n",
    "ppo_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143edeb6",
   "metadata": {},
   "source": [
    "This function loads an agent from the trainer. The RllibAgent class is a wrapper around the core policy, which simplifies pairing and evaluating different type of agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a9df6",
   "metadata": {},
   "source": [
    "## 1.2) Loading BC agent\n",
    "The BC (behavior cloning) agents are trained separately without using Ray. We showed how to train a BC agent in the previous section, and to load a trained agent, we can use the load_bc_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f94ab2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x7fc0e970cf50>,\n",
       " {'eager': True,\n",
       "  'use_lstm': False,\n",
       "  'cell_size': 256,\n",
       "  'data_params': {'layouts': ['cramped_room'],\n",
       "   'check_trajectories': False,\n",
       "   'featurize_states': True,\n",
       "   'data_path': '/Users/jacksonyan/Desktop/project_with_Micah/overcooked_ai/src/human_aware_rl/static/human_data/cleaned/2019_hh_trials_train.pickle'},\n",
       "  'mdp_params': {'layout_name': 'cramped_room', 'old_dynamics': True},\n",
       "  'env_params': {'horizon': 400,\n",
       "   'mlam_params': {'start_orientations': False,\n",
       "    'wait_allowed': False,\n",
       "    'counter_goals': [],\n",
       "    'counter_drop': [],\n",
       "    'counter_pickup': [],\n",
       "    'same_motion_goals': True}},\n",
       "  'mdp_fn_params': {},\n",
       "  'mlp_params': {'num_layers': 2, 'net_arch': [64, 64]},\n",
       "  'training_params': {'epochs': 100,\n",
       "   'validation_split': 0.15,\n",
       "   'batch_size': 64,\n",
       "   'learning_rate': 0.001,\n",
       "   'use_class_weights': False},\n",
       "  'evaluation_params': {'ep_length': 400, 'num_games': 1, 'display': False},\n",
       "  'action_shape': (6,),\n",
       "  'observation_shape': (96,)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from human_aware_rl.imitation.behavior_cloning_tf2 import load_bc_model\n",
    "#this is the same path you used when training the BC agent\n",
    "bc_model_path = \"src/human_aware_rl/imitation/bc_runs/train/cramped_room\"\n",
    "bc_model, bc_params = load_bc_model(bc_model_path)\n",
    "bc_model, bc_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20526ac6",
   "metadata": {},
   "source": [
    "Now that we have loaded the model, since we used Tensorflow to train the agent, we need to wrap it so it is compatible with other agents. We can do it by converting it to a Rllib-compatible policy class, and wraps it as a RllibAgent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c37a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<human_aware_rl.rllib.rllib.RlLibAgent at 0x7fc0effd50d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from human_aware_rl.imitation.behavior_cloning_tf2 import _get_base_ae, BehaviorCloningPolicy\n",
    "bc_policy = BehaviorCloningPolicy.from_model(\n",
    "        bc_model, bc_params, stochastic=True\n",
    "    )\n",
    "# We need the featurization function that is specifically defined for BC agent\n",
    "# The easiest way to do it is to create a base environment from the configuration and extract the featurization function\n",
    "# The environment is also needed to do evaluation\n",
    "\n",
    "base_ae = _get_base_ae(bc_params)\n",
    "base_env = base_ae.env\n",
    "\n",
    "from human_aware_rl.rllib.rllib import RlLibAgent\n",
    "bc_agent = RlLibAgent(bc_policy,0,base_env.featurize_state_mdp)\n",
    "bc_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c5687",
   "metadata": {},
   "source": [
    "Now we have a BC agent that is ready for evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73698e65",
   "metadata": {},
   "source": [
    "## 1.3) Loading & Creating Agent Pair\n",
    "\n",
    "To do evaluation, we need a pair of agents, or an AgentPair. We can directly load a pair of agents for evaluation, which we can do with the load_agent_pair function, or we can create an AgentPair manually from 2 separate RllibAgent instance. To directly load an AgentPair from a trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c3f7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:02:19,320\tWARNING deprecation.py:48 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<overcooked_ai_py.agents.agent.AgentPair at 0x7fc0f124cc10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from human_aware_rl.rllib.rllib import load_agent_pair\n",
    "# if we want to load a self-play agent\n",
    "ap_sp = load_agent_pair(agent_path,\"ppo\",\"ppo\")\n",
    "ap_sp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249778ce",
   "metadata": {},
   "source": [
    "This is convenient when the agents trained are not self-play agents. For example, if we have a PPO agent trained with a BC agent, we can load both as an agent pair at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78bb724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error creating custom logging dir. Falling back to default logdir /Users/jacksonyan/ray_results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 13:04:44,153\tWARNING deprecation.py:48 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<overcooked_ai_py.agents.agent.AgentPair at 0x7fc0f1266e50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_agent_path = \"src/overcooked_demo/server/static/assets/agents/RllibCrampedRoomBC/agent\"\n",
    "ap_bc = load_agent_pair(bc_agent_path,\"ppo\",\"bc\")\n",
    "ap_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd83bc",
   "metadata": {},
   "source": [
    "To create an AgentPair manually, we can just pair together any 2 RllibAgent object. For example, we have created a **ppo_agent** and a **bc_agent**. To pair them up, we can just construct an AgentPair with them as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0acdeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<overcooked_ai_py.agents.agent.AgentPair at 0x7fc0f1251310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from human_aware_rl.rllib.rllib import AgentPair\n",
    "ap = AgentPair(ppo_agent,bc_agent)\n",
    "ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6cafa",
   "metadata": {},
   "source": [
    "# 2): Evaluating AgentPair\n",
    "\n",
    "To evaluate an AgentPair, we need to first create an AgentEvaluator. You can create an AgentEvaluator in various ways, but the simpliest way to do so is from the layout_name. \n",
    "\n",
    "You can modify the settings of the layout by changing the **mdp_params** argument, but most of the time you should only need to include \"layout_name\", which is the layout you want to evaluate the agent pair on, and \"old_dynamics\", which determines whether the envrionment conforms to the design in the Neurips2019 paper, or whether the cooking should start automatically when all ingredients are present.  \n",
    "\n",
    "For the **env_params**, you can change how many steps are there in one evaluation. The default is 400, which means the game runs for 400 timesteps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95787dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<overcooked_ai_py.agents.benchmarking.AgentEvaluator at 0x7fc0f40dcdd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from overcooked_ai_py.agents.benchmarking import AgentEvaluator\n",
    "# Here we create an evaluator for the cramped_room layout\n",
    "layout = \"cramped_room\"\n",
    "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True}, \n",
    "                                     env_params={\"horizon\": 400})\n",
    "ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471aeda",
   "metadata": {},
   "source": [
    "To run evaluations, we can use the evaluate_agent_pair method associated with the AgentEvaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93676beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg rew: 222.00 (std: 10.77, se: 3.41); avg len: 400.00; : 100%|█| 10/10 [00:09<\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ep_returns': array([220, 220, 220, 220, 200, 240, 220, 220, 220, 240]),\n",
       " 'mdp_params': array([{'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]},\n",
       "        {'layout_name': 'cramped_room', 'terrain': [['X', 'X', 'P', 'X', 'X'], ['O', ' ', ' ', ' ', 'O'], ['X', ' ', ' ', ' ', 'X'], ['X', 'D', 'X', 'S', 'X']], 'start_player_positions': [(1, 2), (3, 1)], 'start_bonus_orders': [], 'rew_shaping_params': {'PLACEMENT_IN_POT_REW': 3, 'DISH_PICKUP_REWARD': 3, 'SOUP_PICKUP_REWARD': 5, 'DISH_DISP_DISTANCE_REW': 0, 'POT_DISTANCE_REW': 0, 'SOUP_DISTANCE_REW': 0}, 'start_all_orders': [{'ingredients': ['onion', 'onion', 'onion']}]}],\n",
       "       dtype=object),\n",
       " 'ep_lengths': array([400, 400, 400, 400, 400, 400, 400, 400, 400, 400]),\n",
       " 'ep_dones': array([[False, False, False, ..., False, False, True],\n",
       "        [False, False, False, ..., False, False, True],\n",
       "        [False, False, False, ..., False, False, True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, True],\n",
       "        [False, False, False, ..., False, False, True],\n",
       "        [False, False, False, ..., False, False, True]], dtype=object),\n",
       " 'ep_infos': array([[{'agent_infos': [{'action_probs': array([[0.7036528 , 0.09754185, 0.01395885, 0.08778691, 0.04822406,\n",
       "                 0.04883546]], dtype=float32)}, {'action_probs': array([[0.21080437, 0.04071232, 0.14454994, 0.22968958, 0.23264213,\n",
       "                 0.14160165]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.66688573, 0.22317721, 0.00708428, 0.05211958, 0.03579363,\n",
       "                 0.01493955]], dtype=float32)}, {'action_probs': array([[0.11021239, 0.04065534, 0.35898978, 0.27875417, 0.16411841,\n",
       "                 0.04726987]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.085921  , 0.04419247, 0.01254765, 0.65805113, 0.06675878,\n",
       "                 0.13252893]], dtype=float32)}, {'action_probs': array([[0.06722142, 0.00837827, 0.07990292, 0.1157579 , 0.25486222,\n",
       "                 0.47387722]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         ...,\n",
       "         {'agent_infos': [{'action_probs': array([[0.29419908, 0.15904292, 0.13058963, 0.09716626, 0.10786898,\n",
       "                 0.21113317]], dtype=float32)}, {'action_probs': array([[0.11111562, 0.09163883, 0.16898957, 0.55856794, 0.02074423,\n",
       "                 0.04894377]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.18407577, 0.13644859, 0.06813821, 0.11458357, 0.13731626,\n",
       "                 0.3594376 ]], dtype=float32)}, {'action_probs': array([[0.08052095, 0.01874292, 0.0374771 , 0.0276621 , 0.08240239,\n",
       "                 0.7531946 ]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.06133303, 0.23438175, 0.06269914, 0.42434147, 0.11616037,\n",
       "                 0.1010843 ]], dtype=float32)}, {'action_probs': array([[0.1057082 , 0.06037102, 0.03277464, 0.73282444, 0.03996386,\n",
       "                 0.02835778]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None, 'episode': {'ep_game_stats': {'tomato_pickup': [[], []], 'useful_tomato_pickup': [[], []], 'tomato_drop': [[], []], 'useful_tomato_drop': [[], []], 'potting_tomato': [[], []], 'onion_pickup': [[3, 11, 43, 71, 79, 102, 107, 113, 147, 174, 179, 200, 214, 246, 282, 305, 310, 342, 386], [4, 34, 40, 73, 116, 145, 177, 210, 219, 244, 272, 279, 312, 333, 341, 371, 398]], 'useful_onion_pickup': [[3, 11, 43, 71, 79, 102, 107, 113, 147, 174, 179, 200, 214, 246, 282, 305, 310, 342, 386], [4, 40, 73, 116, 145, 177, 210, 219, 244, 272, 279, 312, 333, 341, 371, 398]], 'onion_drop': [[], []], 'useful_onion_drop': [[], []], 'potting_onion': [[8, 14, 46, 77, 82, 105, 110, 116, 151, 177, 183, 208, 219, 252, 285, 308, 313, 346, 394], [11, 38, 43, 79, 143, 149, 180, 215, 242, 247, 277, 282, 316, 339, 344, 391]], 'dish_pickup': [[30, 132, 235, 267, 333, 362], [61, 87, 159, 199, 302]], 'useful_dish_pickup': [[30, 132, 235, 267, 333, 362], [61, 87, 159, 199, 302]], 'dish_drop': [[], []], 'useful_dish_drop': [[], []], 'soup_pickup': [[34, 136, 239, 273, 336, 380], [66, 102, 171, 203, 305]], 'soup_delivery': [[37, 139, 242, 276, 339, 383], [69, 105, 174, 206, 308]], 'soup_drop': [[], []], 'optimal_onion_potting': [[8, 14, 46, 77, 82, 105, 110, 116, 151, 177, 183, 208, 219, 252, 285, 308, 313, 346, 394], [11, 38, 43, 79, 143, 149, 180, 215, 242, 247, 277, 282, 316, 339, 344, 391]], 'optimal_tomato_potting': [[], []], 'viable_onion_potting': [[8, 14, 46, 77, 82, 105, 110, 116, 151, 177, 183, 208, 219, 252, 285, 308, 313, 346, 394], [11, 38, 43, 79, 143, 149, 180, 215, 242, 247, 277, 282, 316, 339, 344, 391]], 'viable_tomato_potting': [[], []], 'catastrophic_onion_potting': [[], []], 'catastrophic_tomato_potting': [[], []], 'useless_onion_potting': [[], []], 'useless_tomato_potting': [[], []], 'cumulative_sparse_rewards_by_agent': array([120, 100]), 'cumulative_shaped_rewards_by_agent': array([105,  88])}, 'ep_sparse_r': 220, 'ep_shaped_r': 193, 'ep_sparse_r_by_agent': array([120, 100]), 'ep_shaped_r_by_agent': array([105,  88]), 'ep_length': 400}}],\n",
       "        [{'agent_infos': [{'action_probs': array([[0.7036528 , 0.09754185, 0.01395885, 0.08778691, 0.04822406,\n",
       "                 0.04883546]], dtype=float32)}, {'action_probs': array([[0.21080437, 0.04071232, 0.14454994, 0.22968958, 0.23264213,\n",
       "                 0.14160165]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.05907977, 0.03127237, 0.00532675, 0.7713628 , 0.04464763,\n",
       "                 0.08831067]], dtype=float32)}, {'action_probs': array([[0.18678121, 0.02202617, 0.23557004, 0.23477088, 0.20448597,\n",
       "                 0.11636569]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.0066767 , 0.0016865 , 0.00285086, 0.04593066, 0.06299354,\n",
       "                 0.8798617 ]], dtype=float32)}, {'action_probs': array([[0.02506438, 0.01812041, 0.88634354, 0.05953311, 0.00604075,\n",
       "                 0.00489793]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         ...,\n",
       "         {'agent_infos': [{'action_probs': array([[0.3959407 , 0.10240929, 0.15481763, 0.12396351, 0.08807818,\n",
       "                 0.13479063]], dtype=float32)}, {'action_probs': array([[0.06933331, 0.11937079, 0.6653202 , 0.10301267, 0.03800013,\n",
       "                 0.00496286]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.23661262, 0.47312754, 0.12434494, 0.10441339, 0.03228487,\n",
       "                 0.02921657]], dtype=float32)}, {'action_probs': array([[0.6756537 , 0.06326254, 0.00236339, 0.03202648, 0.14786135,\n",
       "                 0.07883257]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.02629578, 0.07239182, 0.00425136, 0.74635637, 0.06170131,\n",
       "                 0.08900332]], dtype=float32)}, {'action_probs': array([[7.7651304e-01, 4.8901491e-02, 4.4684764e-04, 3.2510810e-02,\n",
       "                 8.4240265e-02, 5.7387568e-02]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None, 'episode': {'ep_game_stats': {'tomato_pickup': [[], []], 'useful_tomato_pickup': [[], []], 'tomato_drop': [[], []], 'useful_tomato_drop': [[], []], 'potting_tomato': [[], []], 'onion_pickup': [[3, 8, 37, 70, 84, 99, 135, 161, 169, 203, 231, 238, 268, 292, 299, 304, 331, 337, 362, 372], [4, 27, 36, 42, 58, 67, 102, 125, 132, 171, 194, 201, 208, 235, 242, 267, 300, 334, 368, 375]], 'useful_onion_pickup': [[3, 8, 37, 70, 99, 135, 161, 169, 203, 231, 238, 268, 292, 299, 304, 331, 337, 362, 372], [4, 27, 36, 42, 58, 67, 102, 125, 132, 171, 194, 201, 235, 242, 267, 300, 334, 368, 375]], 'onion_drop': [[355], [46, 214]], 'useful_onion_drop': [[], [46, 214]], 'potting_onion': [[6, 11, 42, 73, 96, 103, 142, 167, 172, 207, 234, 242, 273, 296, 302, 328, 335, 365], [8, 34, 40, 65, 70, 106, 130, 138, 175, 199, 204, 239, 265, 270, 305, 339, 372, 379]], 'dish_pickup': [[26, 57, 124, 191, 248, 257], [88, 160, 222, 284, 322, 351, 391]], 'useful_dish_pickup': [[26, 57, 124, 191, 248], [88, 160, 222, 284, 322, 351, 391]], 'dish_drop': [[256], []], 'useful_dish_drop': [[], []], 'soup_pickup': [[31, 62, 127, 195, 262], [93, 163, 228, 293, 325, 359]], 'soup_delivery': [[34, 65, 130, 198, 265], [98, 166, 231, 297, 329, 362]], 'soup_drop': [[], []], 'optimal_onion_potting': [[6, 11, 42, 73, 96, 103, 142, 167, 172, 207, 234, 242, 273, 296, 302, 328, 335, 365], [8, 34, 40, 65, 70, 106, 130, 138, 175, 199, 204, 239, 265, 270, 305, 339, 372, 379]], 'optimal_tomato_potting': [[], []], 'viable_onion_potting': [[6, 11, 42, 73, 96, 103, 142, 167, 172, 207, 234, 242, 273, 296, 302, 328, 335, 365], [8, 34, 40, 65, 70, 106, 130, 138, 175, 199, 204, 239, 265, 270, 305, 339, 372, 379]], 'viable_tomato_potting': [[], []], 'catastrophic_onion_potting': [[], []], 'catastrophic_tomato_potting': [[], []], 'useless_onion_potting': [[], []], 'useless_tomato_potting': [[], []], 'cumulative_sparse_rewards_by_agent': array([100, 120]), 'cumulative_shaped_rewards_by_agent': array([ 94, 105])}, 'ep_sparse_r': 220, 'ep_shaped_r': 199, 'ep_sparse_r_by_agent': array([100, 120]), 'ep_shaped_r_by_agent': array([ 94, 105]), 'ep_length': 400}}],\n",
       "        [{'agent_infos': [{'action_probs': array([[0.7036528 , 0.09754185, 0.01395885, 0.08778691, 0.04822406,\n",
       "                 0.04883546]], dtype=float32)}, {'action_probs': array([[0.21080437, 0.04071232, 0.14454994, 0.22968958, 0.23264213,\n",
       "                 0.14160165]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.04943704, 0.01342119, 0.01240571, 0.80977654, 0.04933824,\n",
       "                 0.06562129]], dtype=float32)}, {'action_probs': array([[0.11957315, 0.06205623, 0.5160517 , 0.258536  , 0.01936062,\n",
       "                 0.02442229]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.00511688, 0.00283186, 0.00165085, 0.02412008, 0.03862155,\n",
       "                 0.9276588 ]], dtype=float32)}, {'action_probs': array([[0.03749166, 0.00450588, 0.48071322, 0.0806674 , 0.17251565,\n",
       "                 0.22410627]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         ...,\n",
       "         {'agent_infos': [{'action_probs': array([[0.23047817, 0.35374445, 0.13938507, 0.08724292, 0.13733141,\n",
       "                 0.05181786]], dtype=float32)}, {'action_probs': array([[0.09849398, 0.32101637, 0.12579764, 0.19665404, 0.12426755,\n",
       "                 0.13377039]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.11408364, 0.13155408, 0.16876584, 0.34938005, 0.0843102 ,\n",
       "                 0.1519062 ]], dtype=float32)}, {'action_probs': array([[0.15612046, 0.16940527, 0.19250803, 0.28336242, 0.16302237,\n",
       "                 0.03558147]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.12800218, 0.06085579, 0.19051248, 0.34653828, 0.14293967,\n",
       "                 0.13115159]], dtype=float32)}, {'action_probs': array([[0.21294445, 0.15188245, 0.02213552, 0.33472002, 0.16797657,\n",
       "                 0.110341  ]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None, 'episode': {'ep_game_stats': {'tomato_pickup': [[], []], 'useful_tomato_pickup': [[], []], 'tomato_drop': [[], []], 'useful_tomato_drop': [[], []], 'potting_tomato': [[], []], 'onion_pickup': [[2, 8, 16, 36, 49, 69, 102, 137, 158, 167, 172, 198, 234, 241, 272, 286, 306, 338, 367, 372, 381], [3, 37, 72, 85, 93, 101, 108, 133, 168, 200, 228, 240, 271, 304, 330, 336, 376]], 'useful_onion_pickup': [[2, 8, 36, 69, 102, 137, 158, 167, 172, 198, 234, 241, 272, 286, 306, 338, 367, 372, 381], [3, 37, 72, 85, 93, 101, 133, 168, 200, 228, 240, 271, 304, 330, 336, 376]], 'onion_drop': [[], [92]], 'useful_onion_drop': [[], []], 'potting_onion': [[5, 11, 34, 39, 66, 72, 107, 141, 165, 170, 196, 201, 237, 246, 277, 304, 309, 342, 370, 379], [8, 42, 75, 99, 105, 131, 137, 172, 204, 231, 269, 274, 311, 334, 339, 383]], 'dish_pickup': [[78, 114, 210, 254, 328], [24, 53, 155, 189, 285, 363, 395]], 'useful_dish_pickup': [[78, 114, 210, 254, 328], [24, 53, 155, 189, 285, 363, 395]], 'dish_drop': [[], []], 'useful_dish_drop': [[], []], 'soup_pickup': [[95, 127, 224, 266, 331], [31, 62, 161, 193, 297, 367]], 'soup_delivery': [[98, 130, 227, 269, 335], [34, 66, 165, 196, 300, 370]], 'soup_drop': [[], []], 'optimal_onion_potting': [[5, 11, 34, 39, 66, 72, 107, 141, 165, 170, 196, 201, 237, 246, 277, 304, 309, 342, 370, 379], [8, 42, 75, 99, 105, 131, 137, 172, 204, 231, 269, 274, 311, 334, 339, 383]], 'optimal_tomato_potting': [[], []], 'viable_onion_potting': [[5, 11, 34, 39, 66, 72, 107, 141, 165, 170, 196, 201, 237, 246, 277, 304, 309, 342, 370, 379], [8, 42, 75, 99, 105, 131, 137, 172, 204, 231, 269, 274, 311, 334, 339, 383]], 'viable_tomato_potting': [[], []], 'catastrophic_onion_potting': [[], []], 'catastrophic_tomato_potting': [[], []], 'useless_onion_potting': [[], []], 'useless_tomato_potting': [[], []], 'cumulative_sparse_rewards_by_agent': array([100, 120]), 'cumulative_shaped_rewards_by_agent': array([100,  99])}, 'ep_sparse_r': 220, 'ep_shaped_r': 199, 'ep_sparse_r_by_agent': array([100, 120]), 'ep_shaped_r_by_agent': array([100,  99]), 'ep_length': 400}}],\n",
       "        ...,\n",
       "        [{'agent_infos': [{'action_probs': array([[0.7036528 , 0.09754185, 0.01395885, 0.08778691, 0.04822406,\n",
       "                 0.04883546]], dtype=float32)}, {'action_probs': array([[0.21080437, 0.04071232, 0.14454994, 0.22968958, 0.23264213,\n",
       "                 0.14160165]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.05907977, 0.03127237, 0.00532675, 0.7713628 , 0.04464763,\n",
       "                 0.08831067]], dtype=float32)}, {'action_probs': array([[0.18678121, 0.02202617, 0.23557004, 0.23477088, 0.20448597,\n",
       "                 0.11636569]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.00542127, 0.00280747, 0.00100984, 0.04352336, 0.04443868,\n",
       "                 0.9027994 ]], dtype=float32)}, {'action_probs': array([[0.07746643, 0.00712945, 0.71232253, 0.06080749, 0.091703  ,\n",
       "                 0.05057115]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         ...,\n",
       "         {'agent_infos': [{'action_probs': array([[0.03092441, 0.06810096, 0.8035191 , 0.01947824, 0.01836733,\n",
       "                 0.05960986]], dtype=float32)}, {'action_probs': array([[0.07438926, 0.02078033, 0.44691777, 0.19844481, 0.05467205,\n",
       "                 0.20479578]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.59913343, 0.12058972, 0.00107133, 0.09351571, 0.09845322,\n",
       "                 0.0872366 ]], dtype=float32)}, {'action_probs': array([[0.2146893 , 0.08877945, 0.00885143, 0.21548806, 0.20190474,\n",
       "                 0.270287  ]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[1.1416704e-01, 4.3673612e-02, 2.8512953e-04, 8.5267853e-03,\n",
       "                 6.9302745e-02, 7.6404464e-01]], dtype=float32)}, {'action_probs': array([[0.13960595, 0.12240018, 0.21073799, 0.42553478, 0.08395233,\n",
       "                 0.0177688 ]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [5, 0], 'phi_s': None, 'phi_s_prime': None, 'episode': {'ep_game_stats': {'tomato_pickup': [[], []], 'useful_tomato_pickup': [[], []], 'tomato_drop': [[], []], 'useful_tomato_drop': [[], []], 'potting_tomato': [[], []], 'onion_pickup': [[2, 7, 20, 36, 53, 68, 75, 80, 101, 107, 134, 141, 167, 192, 199, 235, 268, 288, 296, 302, 332], [5, 37, 72, 102, 134, 168, 202, 213, 233, 259, 265, 305, 331, 336, 364, 370, 378]], 'useful_onion_pickup': [[2, 7, 20, 36, 68, 75, 101, 107, 134, 141, 167, 192, 199, 235, 268, 288, 296, 302, 332], [5, 37, 72, 102, 134, 168, 202, 213, 233, 265, 305, 331, 336, 364, 370]], 'onion_drop': [[78], []], 'useful_onion_drop': [[78], []], 'potting_onion': [[5, 11, 34, 39, 66, 73, 99, 105, 130, 139, 164, 171, 197, 203, 239, 271, 294, 299, 305, 336], [8, 41, 76, 107, 141, 174, 206, 231, 237, 263, 268, 328, 334, 360, 368, 376]], 'dish_pickup': [[212, 219, 255, 319, 344, 396], [17, 55, 88, 120, 154, 188, 277]], 'useful_dish_pickup': [[212, 255, 319, 344, 396], [17, 55, 88, 120, 154, 188, 277]], 'dish_drop': [[218], []], 'useful_dish_drop': [[], []], 'soup_pickup': [[226, 259, 325, 356, 399], [31, 62, 96, 127, 161, 194, 291]], 'soup_delivery': [[229, 264, 328, 359], [34, 65, 99, 131, 164, 197, 294]], 'soup_drop': [[], []], 'optimal_onion_potting': [[5, 11, 34, 39, 66, 73, 99, 105, 130, 139, 164, 171, 197, 203, 239, 271, 294, 299, 305, 336], [8, 41, 76, 107, 141, 174, 206, 231, 237, 263, 268, 328, 334, 360, 368, 376]], 'optimal_tomato_potting': [[], []], 'viable_onion_potting': [[5, 11, 34, 39, 66, 73, 99, 105, 130, 139, 164, 171, 197, 203, 239, 271, 294, 299, 305, 336], [8, 41, 76, 107, 141, 174, 206, 231, 237, 263, 268, 328, 334, 360, 368, 376]], 'viable_tomato_potting': [[], []], 'catastrophic_onion_potting': [[], []], 'catastrophic_tomato_potting': [[], []], 'useless_onion_potting': [[], []], 'useless_tomato_potting': [[], []], 'cumulative_sparse_rewards_by_agent': array([ 80, 140]), 'cumulative_shaped_rewards_by_agent': array([100, 104])}, 'ep_sparse_r': 220, 'ep_shaped_r': 204, 'ep_sparse_r_by_agent': array([ 80, 140]), 'ep_shaped_r_by_agent': array([100, 104]), 'ep_length': 400}}],\n",
       "        [{'agent_infos': [{'action_probs': array([[0.7036528 , 0.09754185, 0.01395885, 0.08778691, 0.04822406,\n",
       "                 0.04883546]], dtype=float32)}, {'action_probs': array([[0.21080437, 0.04071232, 0.14454994, 0.22968958, 0.23264213,\n",
       "                 0.14160165]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.76102334, 0.14676382, 0.01725871, 0.03892003, 0.02890381,\n",
       "                 0.00713035]], dtype=float32)}, {'action_probs': array([[0.03465187, 0.03658005, 0.53846395, 0.37033176, 0.00966384,\n",
       "                 0.01030853]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.60431683, 0.12855509, 0.06288169, 0.1321035 , 0.05091947,\n",
       "                 0.02122336]], dtype=float32)}, {'action_probs': array([[0.0543362 , 0.03387497, 0.20138294, 0.6754572 , 0.0138055 ,\n",
       "                 0.02114323]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         ...,\n",
       "         {'agent_infos': [{'action_probs': array([[0.04151726, 0.0148285 , 0.01688642, 0.90764546, 0.01011657,\n",
       "                 0.00900574]], dtype=float32)}, {'action_probs': array([[0.1494591 , 0.01384879, 0.45924652, 0.1608278 , 0.03482505,\n",
       "                 0.18179277]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.04706519, 0.0092561 , 0.02375259, 0.8562074 , 0.02192782,\n",
       "                 0.04179092]], dtype=float32)}, {'action_probs': array([[0.0925821 , 0.00643437, 0.12130139, 0.5966005 , 0.01847497,\n",
       "                 0.16460669]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.2203015 , 0.490497  , 0.10315701, 0.03982569, 0.0421377 ,\n",
       "                 0.1040812 ]], dtype=float32)}, {'action_probs': array([[0.1705229 , 0.02352424, 0.02214095, 0.7507415 , 0.00889477,\n",
       "                 0.0241756 ]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None, 'episode': {'ep_game_stats': {'tomato_pickup': [[], []], 'useful_tomato_pickup': [[], []], 'tomato_drop': [[], []], 'useful_tomato_drop': [[], []], 'potting_tomato': [[], []], 'onion_pickup': [[11, 43, 50, 67, 77, 95, 109, 124, 142, 176, 184, 206, 213, 240, 251, 271, 280, 302, 336, 362, 373], [4, 10, 36, 42, 79, 110, 141, 147, 174, 207, 241, 273, 305, 329, 338, 376]], 'useful_onion_pickup': [[11, 43, 67, 77, 109, 142, 176, 206, 213, 240, 271, 302, 336, 362, 373], [4, 10, 42, 79, 110, 141, 147, 174, 207, 241, 273, 305, 338, 376]], 'onion_drop': [[54], []], 'useful_onion_drop': [[54], []], 'potting_onion': [[16, 47, 70, 81, 107, 112, 138, 147, 180, 203, 210, 238, 243, 269, 274, 300, 305, 339, 370, 376], [8, 13, 40, 45, 84, 115, 144, 172, 177, 214, 246, 277, 308, 335, 342, 379]], 'dish_pickup': [[29, 162, 326], [17, 64, 99, 128, 187, 229, 260, 293, 357]], 'useful_dish_pickup': [[162, 326], [17, 64, 99, 128, 187, 229, 260, 293, 357]], 'dish_drop': [[], [22]], 'useful_dish_drop': [[], []], 'soup_pickup': [[36, 168, 329], [67, 104, 135, 200, 234, 266, 297, 367]], 'soup_delivery': [[40, 172, 332], [71, 107, 138, 203, 238, 270, 300, 370]], 'soup_drop': [[], []], 'optimal_onion_potting': [[16, 47, 70, 81, 107, 112, 138, 147, 180, 203, 210, 238, 243, 269, 274, 300, 305, 339, 370, 376], [8, 13, 40, 45, 84, 115, 144, 172, 177, 214, 246, 277, 308, 335, 342, 379]], 'optimal_tomato_potting': [[], []], 'viable_onion_potting': [[16, 47, 70, 81, 107, 112, 138, 147, 180, 203, 210, 238, 243, 269, 274, 300, 305, 339, 370, 376], [8, 13, 40, 45, 84, 115, 144, 172, 177, 214, 246, 277, 308, 335, 342, 379]], 'viable_tomato_potting': [[], []], 'catastrophic_onion_potting': [[], []], 'catastrophic_tomato_potting': [[], []], 'useless_onion_potting': [[], []], 'useless_tomato_potting': [[], []], 'cumulative_sparse_rewards_by_agent': array([ 60, 160]), 'cumulative_shaped_rewards_by_agent': array([ 81, 115])}, 'ep_sparse_r': 220, 'ep_shaped_r': 196, 'ep_sparse_r_by_agent': array([ 60, 160]), 'ep_shaped_r_by_agent': array([ 81, 115]), 'ep_length': 400}}],\n",
       "        [{'agent_infos': [{'action_probs': array([[0.7036528 , 0.09754185, 0.01395885, 0.08778691, 0.04822406,\n",
       "                 0.04883546]], dtype=float32)}, {'action_probs': array([[0.21080437, 0.04071232, 0.14454994, 0.22968958, 0.23264213,\n",
       "                 0.14160165]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.04943704, 0.01342119, 0.01240571, 0.80977654, 0.04933824,\n",
       "                 0.06562129]], dtype=float32)}, {'action_probs': array([[0.11957315, 0.06205623, 0.5160517 , 0.258536  , 0.01936062,\n",
       "                 0.02442229]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.00511688, 0.00283186, 0.00165085, 0.02412008, 0.03862155,\n",
       "                 0.9276588 ]], dtype=float32)}, {'action_probs': array([[0.03749166, 0.00450588, 0.48071322, 0.0806674 , 0.17251565,\n",
       "                 0.22410627]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         ...,\n",
       "         {'agent_infos': [{'action_probs': array([[0.7955295 , 0.05109904, 0.01673106, 0.03556912, 0.02821515,\n",
       "                 0.07285612]], dtype=float32)}, {'action_probs': array([[0.2598827 , 0.24792014, 0.17474934, 0.23481664, 0.05759742,\n",
       "                 0.02503367]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.23883729, 0.00733965, 0.00243962, 0.00549975, 0.05899379,\n",
       "                 0.6868898 ]], dtype=float32)}, {'action_probs': array([[0.04110193, 0.1675043 , 0.01638251, 0.5546472 , 0.07591405,\n",
       "                 0.14444998]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [3, 0], 'phi_s': None, 'phi_s_prime': None},\n",
       "         {'agent_infos': [{'action_probs': array([[0.21662197, 0.309749  , 0.1524019 , 0.14616336, 0.07628692,\n",
       "                 0.09877686]], dtype=float32)}, {'action_probs': array([[0.28212553, 0.15807351, 0.10209871, 0.08399276, 0.14185382,\n",
       "                 0.23185568]], dtype=float32)}], 'sparse_r_by_agent': [0, 0], 'shaped_r_by_agent': [0, 0], 'phi_s': None, 'phi_s_prime': None, 'episode': {'ep_game_stats': {'tomato_pickup': [[], []], 'useful_tomato_pickup': [[], []], 'tomato_drop': [[], []], 'useful_tomato_drop': [[], []], 'potting_tomato': [[], []], 'onion_pickup': [[3, 30, 37, 47, 68, 102, 126, 132, 152, 162, 195, 217, 226, 232, 251, 257, 290, 322, 336, 352, 389, 395], [2, 7, 38, 71, 94, 101, 133, 165, 185, 194, 227, 258, 279, 289, 295, 321, 353, 381, 392]], 'useful_onion_pickup': [[3, 30, 37, 68, 102, 126, 132, 152, 162, 195, 217, 226, 251, 257, 290, 322, 352, 389, 395], [2, 7, 38, 71, 94, 101, 133, 165, 194, 227, 258, 279, 289, 295, 321, 353, 381, 392]], 'onion_drop': [[235], []], 'useful_onion_drop': [[235], []], 'potting_onion': [[9, 35, 41, 66, 72, 106, 130, 135, 160, 165, 200, 224, 229, 255, 260, 295, 327, 350, 355, 393, 398], [5, 11, 43, 75, 98, 104, 137, 168, 192, 197, 231, 263, 287, 292, 318, 324, 357, 390]], 'dish_pickup': [[79, 186, 266, 304, 377], [22, 58, 122, 149, 200, 245, 341]], 'useful_dish_pickup': [[79, 186, 266, 304, 377], [22, 58, 122, 149, 200, 245, 341]], 'dish_drop': [[], []], 'useful_dish_drop': [[], []], 'soup_pickup': [[95, 189, 283, 315, 382], [32, 63, 126, 157, 221, 251, 347]], 'soup_delivery': [[99, 192, 286, 318, 385], [35, 66, 129, 160, 224, 254, 350]], 'soup_drop': [[], []], 'optimal_onion_potting': [[9, 35, 41, 66, 72, 106, 130, 135, 160, 165, 200, 224, 229, 255, 260, 295, 327, 350, 355, 393, 398], [5, 11, 43, 75, 98, 104, 137, 168, 192, 197, 231, 263, 287, 292, 318, 324, 357, 390]], 'optimal_tomato_potting': [[], []], 'viable_onion_potting': [[9, 35, 41, 66, 72, 106, 130, 135, 160, 165, 200, 224, 229, 255, 260, 295, 327, 350, 355, 393, 398], [5, 11, 43, 75, 98, 104, 137, 168, 192, 197, 231, 263, 287, 292, 318, 324, 357, 390]], 'viable_tomato_potting': [[], []], 'catastrophic_onion_potting': [[], []], 'catastrophic_tomato_potting': [[], []], 'useless_onion_potting': [[], []], 'useless_tomato_potting': [[], []], 'cumulative_sparse_rewards_by_agent': array([100, 140]), 'cumulative_shaped_rewards_by_agent': array([103, 110])}, 'ep_sparse_r': 240, 'ep_shaped_r': 213, 'ep_sparse_r_by_agent': array([100, 140]), 'ep_shaped_r_by_agent': array([103, 110]), 'ep_length': 400}}]],\n",
       "       dtype=object),\n",
       " 'env_params': array([{'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1},\n",
       "        {'start_state_fn': None, 'horizon': 400, 'info_level': 0, 'num_mdp': 1}],\n",
       "       dtype=object),\n",
       " 'ep_actions': array([[((-1, 0), (0, 0)), ((0, -1), (1, 0)), ((-1, 0), (0, 0)), ...,\n",
       "         ((0, 0), (1, 0)), ((0, 1), 'interact'), ((-1, 0), (-1, 0))],\n",
       "        [((0, -1), 'interact'), ((-1, 0), (-1, 0)), ((0, 0), (1, 0)), ...,\n",
       "         ((0, -1), (1, 0)), ((0, 1), 'interact'), ((0, -1), (0, -1))],\n",
       "        [((0, -1), (-1, 0)), ((-1, 0), (1, 0)), ('interact', (1, 0)), ...,\n",
       "         ((0, -1), (-1, 0)), ((-1, 0), (1, 0)), ((-1, 0), (-1, 0))],\n",
       "        ...,\n",
       "        [((0, -1), (0, 0)), ((-1, 0), (0, -1)), ('interact', (1, 0)), ...,\n",
       "         ((1, 0), (-1, 0)), ((0, -1), (0, -1)), ('interact', (1, 0))],\n",
       "        [((-1, 0), (-1, 0)), ((0, -1), (-1, 0)), ((0, -1), (-1, 0)), ...,\n",
       "         ((0, 1), (1, 0)), ((-1, 0), (-1, 0)), ((0, 1), (-1, 0))],\n",
       "        [((0, -1), (-1, 0)), ((-1, 0), (1, 0)), ((-1, 0), 'interact'),\n",
       "         ..., ((0, -1), (0, 1)), ('interact', (-1, 0)), ((0, 1), (-1, 0))]],\n",
       "       dtype=object),\n",
       " 'metadatas': {},\n",
       " 'ep_states': array([[<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0b6ebd0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f40d2d90>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f1255790>,\n",
       "         ...,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0b82cd0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0b82e50>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0b82410>],\n",
       "        [<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0bbf0d0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0b82610>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0b82d90>,\n",
       "         ...,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0e78fd0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0e710d0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0e714d0>],\n",
       "        [<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0e718d0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0bbf210>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f0e71450>,\n",
       "         ...,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f380dd50>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0ee5670d0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0ee5674d0>],\n",
       "        ...,\n",
       "        [<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f5166950>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f4ff6ad0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f51669d0>,\n",
       "         ...,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f52d8950>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f52d8cd0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f52d8e50>],\n",
       "        [<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f52d8f10>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f5166a90>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f52d8c10>,\n",
       "         ...,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f5458450>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f5458610>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f54587d0>],\n",
       "        [<overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f4cdc390>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f4cd3cd0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f4cdc250>,\n",
       "         ...,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f55cb110>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f55cb4d0>,\n",
       "         <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState object at 0x7fc0f55cb6d0>]],\n",
       "       dtype=object),\n",
       " 'ep_rewards': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=object)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ap_sp: The AgentPair we created earlier\n",
    "# 10: how many times we should run the evaluation since the policy is stochastic\n",
    "# 400: environment timestep horizon, \n",
    "## should not be necessary is the AgentEvaluator is created with a horizon, but good to have for clarity\n",
    "result = ae.evaluate_agent_pair(ap_sp,10,400)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b6cca",
   "metadata": {},
   "source": [
    "The result returned by the AgentEvaluator contains detailed information about the evaluation runs, including actions taken by each agent at each timestep. Usually you don't need to directly interact with them, but the most direct performance measures can be retrieved with result[\"ep_returns\"], which returns the average sparse reward of each evaluation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fed7df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([220, 220, 220, 220, 200, 240, 220, 220, 220, 240])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"ep_returns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "264f7842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg rew: 156.00 (std: 14.97, se: 4.73); avg len: 400.00; : 100%|█| 10/10 [00:12<\n"
     ]
    }
   ],
   "source": [
    "# we can use any AgentPair class, like the ap_bc object we created earlier\n",
    "# as we can see the performance is not as good as the self-play agents\n",
    "result = ae.evaluate_agent_pair(ap_bc,10,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898bae8",
   "metadata": {},
   "source": [
    "# 3): Visualization\n",
    "\n",
    "We can also visualize the trajectories of agents. One way is to run the web demo with the agents you choose, and the specific instructions can be found in the [overcooked_demo](https://github.com/HumanCompatibleAI/overcooked_ai/tree/master/src/overcooked_demo) module, which requires some setup. Another simpler way is to use the StateVisualizer, which uses the information returned by the AgentEvaluator to create a simple dynamic visualization. You can checkout [this Colab Notebook](https://colab.research.google.com/drive/1AAVP2P-QQhbx6WTOnIG54NXLXFbO7y6n#scrollTo=6Xlu54MkiXCR) that let you play with fixed agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer\n",
    "# here we use the self-play agentPair created earlier again\n",
    "trajs = ae.evaluate_agent_pair(ap_sp,10,400)\n",
    "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b62122",
   "metadata": {},
   "source": [
    "This should spawn a window where you can see what the agents are doing at each timestep. You can drag the slider to go forward and backward in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d470037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c87371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22e439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0d33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106aba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0839354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891c797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "overcooked_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
