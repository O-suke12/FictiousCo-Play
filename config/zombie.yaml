defaults:  
  - _self_  
  - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled  
  
hydra:  
  output_subdir: null  
  run:  
    dir: .

project_name: LILI_and_PPO_MPE

track: False  
agent_num: 2
landmark_num: 2
lili: False
train: True
load_ed: False


test_episode_num: 5
max_cycle:  200  # max timesteps in one episode
max_training_timesteps:  2000000  # break training loop if timeteps > max_training_timesteps
save_model_freq: 100000  
update_timestep: 4000  #update policy every n timesteps
print_freq: 10000  # print avg reward in the interval (in num timesteps)
encoder_decoder_training_timesteps: 500

z_dim: 5
K_epochs: 40  #元は80 update policy for K epochs in one PPO update
eps_clip: 0.2  # clip parameter for PPO
gamma: 0.99  # discount factor
lr_actor: 0.0003  # learning rate for actor network
lr_critic: 0.001  # learning rate for critic network

random_seed: 0  # set random seed if required (0 = no random seed)
