defaults:  
  - _self_  
  - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled  
  
hydra:  
  output_subdir: null  
  run:  
    dir: .

project_name: BachlorThesis_MPE
train: True
track:  False
render: True

max_ep_len:  1000  # max timesteps in one episode
max_training_timesteps: 3000000  # break training loop if timeteps > max_training_timesteps
encoder_decoder_training_timesteps: 10000
print_freq: 10000  # print avg reward in the interval (in num timesteps)
log_freq: 2000  # log avg reward in the interval (in num timesteps)
save_model_freq: 300000  # save model frequency (in num timesteps)

update_timestep: 4000  # update policy every n timesteps
encoder_decoder_update_timestep: 100
K_epochs: 80  # update policy for K epochs in one PPO update

eps_clip: 0.2  # clip parameter for PPO
gamma: 0.99  # discount factor

lr_actor: 0.0003  # learning rate for actor network
lr_critic: 0.001  # learning rate for critic network

random_seed: 0  # set random seed if required (0 = no random seed)